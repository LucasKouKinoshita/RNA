# Verifica se a normalização produziu NAs (ex: se uma coluna tinha todos os valores iguais)
if(any(is.na(X_scaled))) {
cat("Atenção: NAs produzidos durante a normalização. Verifique colunas com variância zero.\n")
# Opção: substituir NAs por 0 ou remover colunas problemáticas
X_scaled[is.na(X_scaled)] <- 0
}
# --- Inicialização de Vetores para Armazenar Resultados de Acurácia ---
all_accuracy_test <- numeric(N_EXECUTIONS)
cat("Iniciando Loop Experimental para Classificação...\n")
cat("----------------------------------------\n")
# --- Loop de Execuções ---
for (exec_num in 1:N_EXECUTIONS) {
cat(paste("\n--- Execução:", exec_num, "de", N_EXECUTIONS, "---\n"))
# 3. Divisão Aleatória dos Dados em Treinamento e Teste
cat("Dividindo dados em conjuntos de treinamento e teste...\n")
set.seed(exec_num) # Garante que a divisão seja diferente a cada execução, mas reprodutível
n_obs <- nrow(X_scaled)
train_indices <- sample(1:n_obs, size = floor(TRAIN_RATIO * n_obs))
x_train <- X_scaled[train_indices, ]
y_train <- Y[train_indices, , drop = FALSE] # Mantém como matriz
x_test <- X_scaled[-train_indices, ]
y_test <- Y[-train_indices, , drop = FALSE] # Mantém como matriz
cat("Treinando a rede MLP para classificação...\n")
# 4. Treinamento da Rede Neural MLP para Classificação
#   - outputActFunc = "Act_TanH" é adequado para alvos -1/1.
#   - linOut = FALSE é o padrão e apropriado quando outputActFunc é especificada.
rede <- mlp(x_train, y_train,
size = HIDDEN_NEURONS,
maxit = MAX_ITERATIONS,
initFunc = "Randomize_Weights",
initFuncParams = c(-0.3, 0.3),
learnFunc = "Rprop",
learnFuncParams = c(0.1, 0.1), # Parâmetros como no script original
updateFunc = "Topological_Order",
updateFuncParams = c(0),
hiddenActFunc = "Act_Logistic", # Função de ativação da camada oculta
outputActFunc = "Act_TanH",     # Função de ativação da camada de SAÍDA
shufflePatterns = TRUE,
inputsTest = x_test,
targetsTest = y_test)
cat("Rede treinada. Realizando previsões no conjunto de teste...\n")
# 5. Previsões e Avaliação no Conjunto de Teste
predicted_outputs_test <- predict(rede, x_test) # Saídas contínuas (entre -1 e 1)
# Converte saídas contínuas em classes discretas (-1 ou 1)
# Um limiar de 0 é natural para a saída da TanH
predicted_classes_test <- ifelse(predicted_outputs_test > 0, 1, -1)
# Calcula a acurácia
correct_predictions <- sum(predicted_classes_test == y_test)
current_accuracy <- correct_predictions / length(y_test)
all_accuracy_test[exec_num] <- current_accuracy
cat(paste("Execução", exec_num, "- Acurácia (teste):", round(current_accuracy, 4), "\n"))
if (exec_num == N_EXECUTIONS) {
plotIterativeError(rede, main = paste("Erro Iterativo da MLP (Última Execução -", MAX_ITERATIONS, "iterações)"))
}
}
cat("----------------------------------------\n")
cat("Loop Experimental Finalizado\n\n")
# --- 6. Resultados Finais (Média e Desvio Padrão da Acurácia) ---
mean_accuracy_test <- mean(all_accuracy_test)
sd_accuracy_test <- sd(all_accuracy_test)
cat("Resultados Finais sobre", N_EXECUTIONS, "execuções (média ± desvio padrão):\n")
cat(paste("Acurácia (teste): ", round(mean_accuracy_test, 4), " ± ", round(sd_accuracy_test, 4), "\n\n"))
cat("----------------------------------------\n")
cat("Script de Classificação Finalizado\n")
graphics.off()
rm(list = ls())
# Carrega as bibliotecas necessárias
library(RSNNS)
library(dplyr) # Embora não usado ativamente no loop principal, pode ser útil para manipulações
library(Metrics) # Usaremos para acurácia, ou calcularemos manualmente
# --- Funções Auxiliares ---
# Função de normalização Min-Max (para as features de entrada)
normalize <- function(x) {
if (min(x, na.rm = TRUE) == max(x, na.rm = TRUE)) {
return(rep(0, length(x))) # Ou rep(0.5, length(x)) ou outra constante
}
return ((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
}
# --- Configurações Globais do Experimento ---
N_EXECUTIONS <- 5       # Número de execuções do experimento
TRAIN_RATIO <- 0.7    # Proporção de dados para treinamento (ex: 0.7 para 70%)
HIDDEN_NEURONS <- 10  # Número de neurônios na camada oculta (ajuste conforme necessário)
MAX_ITERATIONS <- 1000 # Número máximo de iterações (ajuste conforme necessário)
cat("Iniciando Análise: Classificação com Statlog (Heart) Dataset\n")
cat("--------------------------------------------------------------------\n")
# --- 1. Carregamento e Pré-processamento Inicial dos Dados ---
cat("Carregando e pré-processando os dados...\n")
df <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat", sep = " ")
colnames(df) <- c("age", "sex", "chest_pain", "rest_bp", "chol", "fbs", "rest_ecg",
"max_hr", "ex_angina", "oldpeak", "slope", "ca", "thal", "target")
# Remove linhas com NA (se houver após a leitura - 'ca' e 'thal' podem ter '?')
# A conversão para numérico abaixo tratará '?' como NA se não forem espaços
df[df == '?'] <- NA
df <- na.omit(df)
# Converte todas as colunas (exceto target) para numérico
feature_cols <- setdiff(colnames(df), "target")
df[, feature_cols] <- lapply(df[, feature_cols], function(x) as.numeric(as.character(x)))
# Mapeia a variável alvo: Originalmente 1 (ausência) e 2 (presença)
# O usuário mapeou 1 -> -1 (ausência) e 2 -> 1 (presença). Vamos manter isso.
df$target <- ifelse(df$target == 1, -1, 1)
# Verifica se restaram NAs após a conversão e remove-os
df <- na.omit(df)
# Separa features (X) e alvo (Y)
X <- as.matrix(df[, feature_cols])
Y <- as.matrix(df$target) # Y é uma matriz de uma coluna com -1 ou 1
# --- 2. Normalização das Features de Entrada (X) ---
cat("Normalizando as features de entrada (X)...\n")
all_accuracy_test <- numeric(N_EXECUTIONS)
cat("Iniciando Loop Experimental para Classificação...\n")
cat("----------------------------------------\n")
for (exec_num in 1:N_EXECUTIONS) {
cat(paste("\n--- Execução:", exec_num, "de", N_EXECUTIONS, "---\n"))
cat("Dividindo dados em conjuntos de treinamento e teste...\n")
n_obs <- nrow(X)
train_indices <- sample(1:n_obs, size = floor(TRAIN_RATIO * n_obs))
x_train <- X[train_indices, ]
y_train <- Y[train_indices, , drop = FALSE] # Mantém como matriz
x_test <- X[-train_indices, ]
y_test <- Y[-train_indices, , drop = FALSE] # Mantém como matriz
cat("Treinando a rede MLP para classificação...\n")
rede <- mlp(x_train, y_train,
size = HIDDEN_NEURONS,
maxit = MAX_ITERATIONS,
initFunc = "Randomize_Weights",
initFuncParams = c(-0.3, 0.3),
learnFunc = "Rprop",
learnFuncParams = c(0.1, 0.1), # Parâmetros como no script original
updateFunc = "Topological_Order",
updateFuncParams = c(0),
hiddenActFunc = "Act_Logistic", # Função de ativação da camada oculta
outputActFunc = "Act_TanH",     # Função de ativação da camada de SAÍDA
shufflePatterns = TRUE,
inputsTest = x_test,
targetsTest = y_test)
cat("Rede treinada. Realizando previsões no conjunto de teste...\n")
predicted_outputs_test <- predict(rede, x_test) # Saídas contínuas (entre -1 e 1)
H
predicted_classes_test <- ifelse(predicted_outputs_test > 0, 1, -1)
correct_predictions <- sum(predicted_classes_test == y_test)
current_accuracy <- correct_predictions / length(y_test)
all_accuracy_test[exec_num] <- current_accuracy
cat(paste("Execução", exec_num, "- Acurácia (teste):", round(current_accuracy, 4), "\n"))
if (exec_num == N_EXECUTIONS) {
plotIterativeError(rede, main = paste("Erro Iterativo da MLP (Última Execução -", MAX_ITERATIONS, "iterações)"))
}
}
graphics.off()
rm(list = ls())
# Carrega as bibliotecas necessárias
library(RSNNS)
library(dplyr) # Embora não usado ativamente no loop principal, pode ser útil para manipulações
library(Metrics) # Usaremos para acurácia, ou calcularemos manualmente
# --- Funções Auxiliares ---
# Função de normalização Min-Max (para as features de entrada)
normalize <- function(x) {
if (min(x, na.rm = TRUE) == max(x, na.rm = TRUE)) {
return(rep(0, length(x))) # Ou rep(0.5, length(x)) ou outra constante
}
return ((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
}
# --- Configurações Globais do Experimento ---
N_EXECUTIONS <- 5       # Número de execuções do experimento
TRAIN_RATIO <- 0.7    # Proporção de dados para treinamento (ex: 0.7 para 70%)
HIDDEN_NEURONS <- 10  # Número de neurônios na camada oculta (ajuste conforme necessário)
MAX_ITERATIONS <- 1000 # Número máximo de iterações (ajuste conforme necessário)
cat("Iniciando Análise: Classificação com Statlog (Heart) Dataset\n")
cat("--------------------------------------------------------------------\n")
# --- 1. Carregamento e Pré-processamento Inicial dos Dados ---
cat("Carregando e pré-processando os dados...\n")
df <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat", sep = " ")
colnames(df) <- c("age", "sex", "chest_pain", "rest_bp", "chol", "fbs", "rest_ecg",
"max_hr", "ex_angina", "oldpeak", "slope", "ca", "thal", "target")
# Remove linhas com NA (se houver após a leitura - 'ca' e 'thal' podem ter '?')
# A conversão para numérico abaixo tratará '?' como NA se não forem espaços
df[df == '?'] <- NA
df <- na.omit(df)
# Converte todas as colunas (exceto target) para numérico
feature_cols <- setdiff(colnames(df), "target")
df[, feature_cols] <- lapply(df[, feature_cols], function(x) as.numeric(as.character(x)))
# Mapeia a variável alvo: Originalmente 1 (ausência) e 2 (presença)
# O usuário mapeou 1 -> -1 (ausência) e 2 -> 1 (presença). Vamos manter isso.
df$target <- ifelse(df$target == 1, -1, 1)
# Verifica se restaram NAs após a conversão e remove-os
df <- na.omit(df)
# Separa features (X) e alvo (Y)
X <- as.matrix(df[, feature_cols])
Y <- as.matrix(df$target) # Y é uma matriz de uma coluna com -1 ou 1
# --- 2. Normalização das Features de Entrada (X) ---
cat("Normalizando as features de entrada (X)...\n")
# Aplica a normalização para cada coluna de X
X_scaled <- apply(X, 2, normalize)
# Verifica se a normalização produziu NAs (ex: se uma coluna tinha todos os valores iguais)
if(any(is.na(X_scaled))) {
cat("Atenção: NAs produzidos durante a normalização. Verifique colunas com variância zero.\n")
# Opção: substituir NAs por 0 ou remover colunas problemáticas
X_scaled[is.na(X_scaled)] <- 0
}
all_accuracy_test <- numeric(N_EXECUTIONS)
cat("Iniciando Loop Experimental para Classificação...\n")
cat("----------------------------------------\n")
for (exec_num in 1:N_EXECUTIONS) {
cat(paste("\n--- Execução:", exec_num, "de", N_EXECUTIONS, "---\n"))
cat("Dividindo dados em conjuntos de treinamento e teste...\n")
n_obs <- nrow(X_scaled)
train_indices <- sample(1:n_obs, size = floor(TRAIN_RATIO * n_obs))
x_train <- X_scaled[train_indices, ]
y_train <- Y[train_indices, , drop = FALSE] # Mantém como matriz
x_test <- X_scaled[-train_indices, ]
y_test <- Y[-train_indices, , drop = FALSE] # Mantém como matriz
cat("Treinando a rede MLP para classificação...\n")
rede <- mlp(x_train, y_train,
size = HIDDEN_NEURONS,
maxit = MAX_ITERATIONS,
initFunc = "Randomize_Weights",
initFuncParams = c(-0.3, 0.3),
learnFunc = "Rprop",
learnFuncParams = c(0.1, 0.1), # Parâmetros como no script original
updateFunc = "Topological_Order",
updateFuncParams = c(0),
hiddenActFunc = "Act_Logistic", # Função de ativação da camada oculta
outputActFunc = "Act_TanH",     # Função de ativação da camada de SAÍDA
shufflePatterns = TRUE,
inputsTest = x_test,
targetsTest = y_test)
cat("Rede treinada. Realizando previsões no conjunto de teste...\n")
predicted_outputs_test <- predict(rede, x_test) # Saídas contínuas (entre -1 e 1)
H
predicted_classes_test <- ifelse(predicted_outputs_test > 0, 1, -1)
# Calcula a acurácia
correct_predictions <- sum(predicted_classes_test == y_test)
current_accuracy <- correct_predictions / length(y_test)
all_accuracy_test[exec_num] <- current_accuracy
cat(paste("Execução", exec_num, "- Acurácia (teste):", round(current_accuracy, 4), "\n"))
if (exec_num == N_EXECUTIONS) {
plotIterativeError(rede, main = paste("Erro Iterativo da MLP (Última Execução -", MAX_ITERATIONS, "iterações)"))
}
}
graphics.off()
rm(list = ls())
# Carrega as bibliotecas necessárias
library(RSNNS)
library(dplyr) # Embora não usado ativamente no loop principal, pode ser útil para manipulações
library(Metrics) # Usaremos para acurácia, ou calcularemos manualmente
# --- Funções Auxiliares ---
# Função de normalização Min-Max (para as features de entrada)
normalize <- function(x) {
# Verifica se todos os valores são iguais para evitar divisão por zero
if (min(x, na.rm = TRUE) == max(x, na.rm = TRUE)) {
return(rep(0, length(x))) # Ou rep(0.5, length(x)) ou outra constante
}
return ((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
}
# --- Configurações Globais do Experimento ---
N_EXECUTIONS <- 5       # Número de execuções do experimento
TRAIN_RATIO <- 0.7    # Proporção de dados para treinamento (ex: 0.7 para 70%)
HIDDEN_NEURONS <- 10  # Número de neurônios na camada oculta (ajuste conforme necessário)
MAX_ITERATIONS <- 1000 # Número máximo de iterações (ajuste conforme necessário)
cat("Iniciando Análise: Classificação com Statlog (Heart) Dataset\n")
cat("--------------------------------------------------------------------\n")
# --- 1. Carregamento e Pré-processamento Inicial dos Dados ---
cat("Carregando e pré-processando os dados...\n")
df <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat", sep = " ")
colnames(df) <- c("age", "sex", "chest_pain", "rest_bp", "chol", "fbs", "rest_ecg",
"max_hr", "ex_angina", "oldpeak", "slope", "ca", "thal", "target")
# Remove linhas com NA (se houver após a leitura - 'ca' e 'thal' podem ter '?')
# A conversão para numérico abaixo tratará '?' como NA se não forem espaços
df[df == '?'] <- NA
df <- na.omit(df)
# Converte todas as colunas (exceto target) para numérico
feature_cols <- setdiff(colnames(df), "target")
df[, feature_cols] <- lapply(df[, feature_cols], function(x) as.numeric(as.character(x)))
# Mapeia a variável alvo: Originalmente 1 (ausência) e 2 (presença)
# O usuário mapeou 1 -> -1 (ausência) e 2 -> 1 (presença). Vamos manter isso.
df$target <- ifelse(df$target == 1, -1, 1)
# Verifica se restaram NAs após a conversão e remove-os
df <- na.omit(df)
# Separa features (X) e alvo (Y)
X <- as.matrix(df[, feature_cols])
Y <- as.matrix(df$target) # Y é uma matriz de uma coluna com -1 ou 1
# --- 2. Normalização das Features de Entrada (X) ---
cat("Normalizando as features de entrada (X)...\n")
# Aplica a normalização para cada coluna de X
X_scaled <- apply(X, 2, normalize)
# Verifica se a normalização produziu NAs (ex: se uma coluna tinha todos os valores iguais)
if(any(is.na(X_scaled))) {
cat("Atenção: NAs produzidos durante a normalização. Verifique colunas com variância zero.\n")
# Opção: substituir NAs por 0 ou remover colunas problemáticas
X_scaled[is.na(X_scaled)] <- 0
}
# --- Inicialização de Vetores para Armazenar Resultados de Acurácia ---
all_accuracy_test <- numeric(N_EXECUTIONS)
cat("Iniciando Loop Experimental para Classificação...\n")
cat("----------------------------------------\n")
# --- Loop de Execuções ---
for (exec_num in 1:N_EXECUTIONS) {
cat(paste("\n--- Execução:", exec_num, "de", N_EXECUTIONS, "---\n"))
# 3. Divisão Aleatória dos Dados em Treinamento e Teste
cat("Dividindo dados em conjuntos de treinamento e teste...\n")
set.seed(exec_num) # Garante que a divisão seja diferente a cada execução, mas reprodutível
n_obs <- nrow(X_scaled)
train_indices <- sample(1:n_obs, size = floor(TRAIN_RATIO * n_obs))
x_train <- X_scaled[train_indices, ]
y_train <- Y[train_indices, , drop = FALSE] # Mantém como matriz
x_test <- X_scaled[-train_indices, ]
y_test <- Y[-train_indices, , drop = FALSE] # Mantém como matriz
cat("Treinando a rede MLP para classificação...\n")
# 4. Treinamento da Rede Neural MLP para Classificação
#   - outputActFunc = "Act_TanH" é adequado para alvos -1/1.
#   - linOut = FALSE é o padrão e apropriado quando outputActFunc é especificada.
rede <- mlp(x_train, y_train,
size = HIDDEN_NEURONS,
maxit = MAX_ITERATIONS,
initFunc = "Randomize_Weights",
initFuncParams = c(-0.3, 0.3),
learnFunc = "Rprop",
learnFuncParams = c(0.1, 0.1), # Parâmetros como no script original
updateFunc = "Topological_Order",
updateFuncParams = c(0),
hiddenActFunc = "Act_Logistic", # Função de ativação da camada oculta
outputActFunc = "Act_TanH",     # Função de ativação da camada de SAÍDA
shufflePatterns = TRUE,
inputsTest = x_test,
targetsTest = y_test)
cat("Rede treinada. Realizando previsões no conjunto de teste...\n")
# 5. Previsões e Avaliação no Conjunto de Teste
predicted_outputs_test <- predict(rede, x_test) # Saídas contínuas (entre -1 e 1)
# Converte saídas contínuas em classes discretas (-1 ou 1)
# Um limiar de 0 é natural para a saída da TanH
predicted_classes_test <- ifelse(predicted_outputs_test > 0, 1, -1)
# Calcula a acurácia
correct_predictions <- sum(predicted_classes_test == y_test)
current_accuracy <- correct_predictions / length(y_test)
all_accuracy_test[exec_num] <- current_accuracy
cat(paste("Execução", exec_num, "- Acurácia (teste):", round(current_accuracy, 4), "\n"))
if (exec_num == N_EXECUTIONS) {
plotIterativeError(rede, main = paste("Erro Iterativo da MLP (Última Execução -", MAX_ITERATIONS, "iterações)"))
}
}
cat("----------------------------------------\n")
cat("Loop Experimental Finalizado\n\n")
# --- 6. Resultados Finais (Média e Desvio Padrão da Acurácia) ---
mean_accuracy_test <- mean(all_accuracy_test)
sd_accuracy_test <- sd(all_accuracy_test)
cat("Resultados Finais sobre", N_EXECUTIONS, "execuções (média ± desvio padrão):\n")
cat(paste("Acurácia (teste): ", round(mean_accuracy_test, 4), " ± ", round(sd_accuracy_test, 4), "\n\n"))
cat("----------------------------------------\n")
cat("Script de Classificação Finalizado\n")
graphics.off()
rm(list = ls())
# Carrega as bibliotecas necessárias
library(RSNNS)
library(dplyr) # Embora não usado ativamente no loop principal, pode ser útil para manipulações
library(Metrics) # Usaremos para acurácia, ou calcularemos manualmente
# --- Configurações Globais do Experimento ---
N_EXECUTIONS <- 5       # Número de execuções do experimento
TRAIN_RATIO <- 0.7    # Proporção de dados para treinamento (ex: 0.7 para 70%)
HIDDEN_NEURONS <- 10  # Número de neurônios na camada oculta (ajuste conforme necessário)
MAX_ITERATIONS <- 1000 # Número máximo de iterações (ajuste conforme necessário)
cat("Iniciando Análise: Classificação com Statlog (Heart) Dataset\n")
cat("--------------------------------------------------------------------\n")
# --- 1. Carregamento e Pré-processamento Inicial dos Dados ---
cat("Carregando e pré-processando os dados...\n")
df <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat", sep = " ")
colnames(df) <- c("age", "sex", "chest_pain", "rest_bp", "chol", "fbs", "rest_ecg",
"max_hr", "ex_angina", "oldpeak", "slope", "ca", "thal", "target")
# Remove linhas com NA (se houver após a leitura - 'ca' e 'thal' podem ter '?')
# A conversão para numérico abaixo tratará '?' como NA se não forem espaços
df[df == '?'] <- NA
df <- na.omit(df)
# Converte todas as colunas (exceto target) para numérico
feature_cols <- setdiff(colnames(df), "target")
df[, feature_cols] <- lapply(df[, feature_cols], function(x) as.numeric(as.character(x)))
# Mapeia a variável alvo: Originalmente 1 (ausência) e 2 (presença)
# O usuário mapeou 1 -> -1 (ausência) e 2 -> 1 (presença). Vamos manter isso.
df$target <- ifelse(df$target == 1, -1, 1)
# Verifica se restaram NAs após a conversão e remove-os
df <- na.omit(df)
# Separa features (X) e alvo (Y)
X <- as.matrix(df[, feature_cols])
Y <- as.matrix(df$target) # Y é uma matriz de uma coluna com -1 ou 1
# --- 2. Normalização das Features de Entrada (X) ---
cat("Normalizando as features de entrada (X)...\n")
# Aplica a normalização para cada coluna de X
# --- Inicialização de Vetores para Armazenar Resultados de Acurácia ---
all_accuracy_test <- numeric(N_EXECUTIONS)
cat("Iniciando Loop Experimental para Classificação...\n")
cat("----------------------------------------\n")
# --- Loop de Execuções ---
for (exec_num in 1:N_EXECUTIONS) {
cat(paste("\n--- Execução:", exec_num, "de", N_EXECUTIONS, "---\n"))
# 3. Divisão Aleatória dos Dados em Treinamento e Teste
cat("Dividindo dados em conjuntos de treinamento e teste...\n")
set.seed(exec_num) # Garante que a divisão seja diferente a cada execução, mas reprodutível
n_obs <- nrow(X)
train_indices <- sample(1:n_obs, size = floor(TRAIN_RATIO * n_obs))
x_train <- X[train_indices, ]
y_train <- Y[train_indices, , drop = FALSE] # Mantém como matriz
x_test <- X[-train_indices, ]
y_test <- Y[-train_indices, , drop = FALSE] # Mantém como matriz
cat("Treinando a rede MLP para classificação...\n")
# 4. Treinamento da Rede Neural MLP para Classificação
#   - outputActFunc = "Act_TanH" é adequado para alvos -1/1.
#   - linOut = FALSE é o padrão e apropriado quando outputActFunc é especificada.
rede <- mlp(x_train, y_train,
size = HIDDEN_NEURONS,
maxit = MAX_ITERATIONS,
initFunc = "Randomize_Weights",
initFuncParams = c(-0.3, 0.3),
learnFunc = "Rprop",
learnFuncParams = c(0.1, 0.1), # Parâmetros como no script original
updateFunc = "Topological_Order",
updateFuncParams = c(0),
hiddenActFunc = "Act_Logistic", # Função de ativação da camada oculta
outputActFunc = "Act_TanH",     # Função de ativação da camada de SAÍDA
shufflePatterns = TRUE,
inputsTest = x_test,
targetsTest = y_test)
cat("Rede treinada. Realizando previsões no conjunto de teste...\n")
# 5. Previsões e Avaliação no Conjunto de Teste
predicted_outputs_test <- predict(rede, x_test) # Saídas contínuas (entre -1 e 1)
# Converte saídas contínuas em classes discretas (-1 ou 1)
# Um limiar de 0 é natural para a saída da TanH
predicted_classes_test <- ifelse(predicted_outputs_test > 0, 1, -1)
# Calcula a acurácia
correct_predictions <- sum(predicted_classes_test == y_test)
current_accuracy <- correct_predictions / length(y_test)
all_accuracy_test[exec_num] <- current_accuracy
cat(paste("Execução", exec_num, "- Acurácia (teste):", round(current_accuracy, 4), "\n"))
if (exec_num == N_EXECUTIONS) {
plotIterativeError(rede, main = paste("Erro Iterativo da MLP (Última Execução -", MAX_ITERATIONS, "iterações)"))
}
}
cat("----------------------------------------\n")
cat("Loop Experimental Finalizado\n\n")
# --- 6. Resultados Finais (Média e Desvio Padrão da Acurácia) ---
mean_accuracy_test <- mean(all_accuracy_test)
sd_accuracy_test <- sd(all_accuracy_test)
cat("Resultados Finais sobre", N_EXECUTIONS, "execuções (média ± desvio padrão):\n")
cat(paste("Acurácia (teste): ", round(mean_accuracy_test, 4), " ± ", round(sd_accuracy_test, 4), "\n\n"))
cat("----------------------------------------\n")
cat("Script de Classificação Finalizado\n")
graphics.off()
rm(list = ls())
library(RSNNS)
library(dplyr)
library(Metrics)
N_EXECUTIONS <- 5
TRAIN_RATIO <- 0.7
HIDDEN_NEURONS <- 10
MAX_ITERATIONS <- 1000
cat("Iniciando Análise: Classificação com Statlog (Heart) Dataset\n")
cat("--------------------------------------------------------------------\n")
cat("Carregando e pré-processando os dados...\n")
df <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat", sep = " ")
colnames(df) <- c("age", "sex", "chest_pain", "rest_bp", "chol", "fbs", "rest_ecg",
"max_hr", "ex_angina", "oldpeak", "slope", "ca", "thal", "target")
df[df == '?'] <- NA
df <- na.omit(df)
feature_cols <- setdiff(colnames(df), "target")
df[, feature_cols] <- lapply(df[, feature_cols], function(x) as.numeric(as.character(x)))
df$target <- ifelse(df$target == 1, -1, 1)
df <- na.omit(df)
X <- as.matrix(df[, feature_cols])
Y <- as.matrix(df$target) # Y é uma matriz de uma coluna com -1 ou 1
# --- Inicialização de Vetores para Armazenar Resultados de Acurácia ---
all_accuracy_test <- numeric(N_EXECUTIONS)
cat("Iniciando Loop Experimental para Classificação...\n")
cat("----------------------------------------\n")
# --- Loop de Execuções ---
for (exec_num in 1:N_EXECUTIONS) {
cat(paste("\n--- Execução:", exec_num, "de", N_EXECUTIONS, "---\n"))
cat("Dividindo dados em conjuntos de treinamento e teste...\n")
n_obs <- nrow(X)
train_indices <- sample(1:n_obs, size = floor(TRAIN_RATIO * n_obs))
x_train <- X[train_indices, ]
y_train <- Y[train_indices, , drop = FALSE] # Mantém como matriz
x_test <- X[-train_indices, ]
y_test <- Y[-train_indices, , drop = FALSE] # Mantém como matriz
cat("Treinando a rede MLP para classificação...\n")
rede <- mlp(x_train, y_train,
size = HIDDEN_NEURONS,
maxit = MAX_ITERATIONS,
initFunc = "Randomize_Weights",
initFuncParams = c(-0.3, 0.3),
learnFunc = "Rprop",
learnFuncParams = c(0.1, 0.1),
updateFunc = "Topological_Order",
updateFuncParams = c(0),
hiddenActFunc = "Act_Logistic",
outputActFunc = "Act_TanH",     # Função de ativação da camada de SAÍDA
shufflePatterns = TRUE,
inputsTest = x_test,
targetsTest = y_test)
cat("Rede treinada. Realizando previsões no conjunto de teste...\n")
predicted_outputs_test <- predict(rede, x_test)
predicted_classes_test <- ifelse(predicted_outputs_test > 0, 1, -1)
correct_predictions <- sum(predicted_classes_test == y_test)
current_accuracy <- correct_predictions / length(y_test)
all_accuracy_test[exec_num] <- current_accuracy
cat(paste("Execução", exec_num, "- Acurácia (teste):", round(current_accuracy, 4), "\n"))
if (exec_num == N_EXECUTIONS) {
plotIterativeError(rede, main = paste("Erro Iterativo da MLP (Última Execução -", MAX_ITERATIONS, "iterações)"))
}
}
cat("----------------------------------------\n")
cat("Loop Experimental Finalizado\n\n")
mean_accuracy_test <- mean(all_accuracy_test)
sd_accuracy_test <- sd(all_accuracy_test)
cat("Resultados Finais sobre", N_EXECUTIONS, "execuções (média ± desvio padrão):\n")
cat(paste("Acurácia (teste): ", round(mean_accuracy_test, 4), " ± ", round(sd_accuracy_test, 4), "\n\n"))
cat("----------------------------------------\n")
cat("Script de Classificação Finalizado\n")
